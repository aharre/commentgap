---
title: "03_Code_Sorting policies"
output: html_document
date: "2023-08-07"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyr)
library(ggplot2)

head(comment_data_general)
```

# subset
```{r}

comment_data_general %>% group_by(article) %>% summarise(comments = n()) %>% arrange(desc(comments))

which(unique(comment_data_general$article) == "/story/2000140091025/thomas-schmid-belastet-kurz-benko-sobotka-und-zahlreiche-weggefaehrten-aus")


comment_data_1 <- comment_data_general %>% 
  filter(article == "/story/2000140091025/thomas-schmid-belastet-kurz-benko-sobotka-und-zahlreiche-weggefaehrten-aus")

head(comment_data_1)

```



#Sorting policies - 1 DISCUSSION

##I. Replies hidden
```{r}
# CHRONOLOGICAL
  # without pinned posts
  df_sort1 <- comment_data_1 %>% group_by(article) %>% 
    filter(is_root_comment == 1) %>% # hidden replies
    arrange(article, timestamp_f) # chronological
  
  # with pinned posts
  df_sort2 <- comment_data_1 %>% group_by(article) %>%
    filter(is_root_comment == 1) %>% # hidden replies
    arrange(article, desc(pinned_f), timestamp_f) # pinned, then chronological
  
  # REVERSE CHRONOLOGICAL
  # without pinned posts
  df_sort3 <- comment_data_1 %>% group_by(article) %>% 
    filter(is_root_comment == 1) %>% # hidden replies
    arrange(article, desc(timestamp_f)) # reverse chronological
  
  # with pinned posts
  df_sort4 <- comment_data_1 %>% group_by(article) %>%
    filter(is_root_comment == 1) %>% # hidden replies
    arrange(article, desc(pinned_f), desc(timestamp_f)) # pinned, then reverse chronological
  
  # MOST POSITIVE ABSOLUTE
  # without pinned posts
  df_sort5 <- comment_data_1 %>% group_by(article) %>% 
    filter(is_root_comment == 1) %>% # hidden replies
    arrange(article, desc(votes_pos)) # most positive
  
  # with pinned posts
  df_sort6 <- comment_data_1 %>% group_by(article) %>%
    filter(is_root_comment == 1) %>% # hidden replies
    arrange(article, desc(pinned_f), desc(votes_pos)) # pinned, then most positive
  
  # MOST POSITIVE RELATIVE
  # without pinned posts
  df_sort7 <- comment_data_1 %>% group_by(article) %>% 
    filter(is_root_comment == 1) %>% # hidden replies
    arrange(article, desc(votes_rel)) # most positive
  
  # with pinned posts
  df_sort8 <- comment_data_1 %>% group_by(article) %>%
    filter(is_root_comment == 1) %>% # hidden replies
    arrange(article, desc(pinned_f), desc(votes_rel)) # pinned, then most positive
  
  # MOST NEGATIVE ABSOLUTE
  # without pinned posts
  df_sort9 <- comment_data_1 %>% group_by(article) %>% 
    filter(is_root_comment == 1) %>% # hidden replies
    arrange(article, desc(votes_neg)) # most negative
  
  # with pinned posts
  df_sort10 <- comment_data_1 %>% group_by(article) %>%
    filter(is_root_comment == 1) %>% # hidden replies
    arrange(article, desc(pinned_f), desc(votes_neg)) # pinned, then most negative
  
  # LEAST NEGATIVE ABSOLUTE
  # without pinned posts
  df_sort11 <- comment_data_1 %>% group_by(article) %>% 
    filter(is_root_comment == 1) %>% # hidden replies
    arrange(article, votes_neg) # least negative
  
  # with pinned posts
  df_sort12 <- comment_data_1 %>% group_by(article) %>%
    filter(is_root_comment == 1) %>% # hidden replies
    arrange(article, desc(pinned_f), votes_neg) # pinned, then least negative

```

##II. Replies shown in tree
```{r}
# calculates reply-tree sorting policies for 1 discussion
  # comment_data_1 is the dataset for 1 discussion
  # returns df_sort_list_rt
  # arrange only roots chronologically but show replies beneath
  
  # get CHRONOLOGICAL order of root posts only
  root_order <- comment_data_1 %>% filter(is_root_comment==1) %>% arrange(timestamp_f) %>% select(root_of_tree)
  root_order$order_roots <- 1:nrow(root_order)
  comment_data_2 <- merge(comment_data_1, root_order, by = "root_of_tree", all.x=TRUE, sort = FALSE)
  
  # get CHRONOLOGICAL order of root posts only WITH PINNED
  root_order <- comment_data_1 %>% filter(is_root_comment==1) %>% arrange(pinned_f, timestamp_f) %>% select(root_of_tree)
  root_order$order_roots <- 1:nrow(root_order)
  comment_data_3 <- merge(comment_data_1, root_order, by = "root_of_tree", all.x=TRUE, sort = FALSE)

  # CHRONOLOGICAL
  # without pinned posts
  df_sort13 <- comment_data_2 %>% group_by(article) %>% 
    arrange(article, order_roots, order) # chronological
  
  # with pinned posts
  df_sort14 <- comment_data_3 %>% group_by(article) %>%
    arrange(article, order_roots, order) # pinned, then chronological
  
  # REVERSE CHRONOLOGICAL
  # without pinned posts
  df_sort15 <- comment_data_2 %>% group_by(article) %>%  
    arrange(article, desc(order_roots), order) # rev chronological
  
  # with pinned posts
  df_sort16 <- comment_data_3 %>% group_by(article) %>%  
    arrange(article, desc(order_roots), order) # pinned, then rev chronological

  
  # get VOTES_POS order of root posts only (high to low)
  root_order <- comment_data_1 %>% filter(is_root_comment==1) %>% arrange(desc(votes_pos)) %>% select(root_of_tree)
  root_order$order_roots <- 1:nrow(root_order)
  comment_data_4 <- merge(comment_data_1, root_order, by = "root_of_tree", all.x=TRUE, sort = FALSE)
  
  # get VOTES_POS order of root posts only WITH PINNED (high to low)
  root_order <- comment_data_1 %>% filter(is_root_comment==1) %>% arrange(pinned_f, desc(votes_pos)) %>% select(root_of_tree)
  root_order$order_roots <- 1:nrow(root_order)
  comment_data_5 <- merge(comment_data_1, root_order, by = "root_of_tree", all.x=TRUE, sort = FALSE)
  
  # MOST POSITIVE ABSOLUTE
  # without pinned posts
  df_sort17 <- comment_data_4 %>% group_by(article) %>% 
    arrange(article, order_roots, order) # most positive roots
  
  # with pinned posts
  df_sort18 <- comment_data_5 %>% group_by(article) %>%
    arrange(article, order_roots, order) # pinned, then most positive roots, then replies
  
  
  
  
  # get VOTES_REL order of root posts only (high to low)
  root_order <- comment_data_1 %>% filter(is_root_comment==1) %>% arrange(desc(votes_rel)) %>% select(root_of_tree)
  root_order$order_roots <- 1:nrow(root_order)
  comment_data_6 <- merge(comment_data_1, root_order, by = "root_of_tree", all.x=TRUE, sort = FALSE)
  
  # get VOTES_REL order of root posts only WITH PINNED (high to low)
  root_order <- comment_data_1 %>% filter(is_root_comment==1) %>% arrange(pinned_f, desc(votes_rel)) %>% select(root_of_tree)
  root_order$order_roots <- 1:nrow(root_order)
  comment_data_7 <- merge(comment_data_1, root_order, by = "root_of_tree", all.x=TRUE, sort = FALSE)
  
  # MOST POSITIVE RELATIVE
  # without pinned posts
  df_sort19 <- comment_data_6 %>% group_by(article) %>% 
    arrange(article, order_roots, order) # most positive
  
  # with pinned posts
  df_sort20 <- comment_data_7 %>% group_by(article) %>%
    arrange(article, order_roots, order) # pinned, then most positive
  
  
  
  
  # get VOTES_NEG order of root posts only (high to low)
  root_order <- comment_data_1 %>% filter(is_root_comment==1) %>% arrange(desc(votes_neg)) %>% select(root_of_tree)
  root_order$order_roots <- 1:nrow(root_order)
  comment_data_8 <- merge(comment_data_1, root_order, by = "root_of_tree", all.x=TRUE, sort = FALSE)
  
  # get VOTES_NEG order of root posts only WITH PINNED (high to low)
  root_order <- comment_data_1 %>% filter(is_root_comment==1) %>% arrange(pinned_f, desc(votes_neg)) %>% select(root_of_tree)
  root_order$order_roots <- 1:nrow(root_order)
  comment_data_9 <- merge(comment_data_1, root_order, by = "root_of_tree", all.x=TRUE, sort = FALSE)
  
  # MOST NEGATIVE ABSOLUTE
  # without pinned posts
  df_sort21 <- comment_data_8 %>% group_by(article) %>% 
    arrange(article, order_roots, order) # most negative roots, then replies
  
  # with pinned posts
  df_sort22 <- comment_data_9 %>% group_by(article) %>%
    arrange(article, order_roots, order) # pinned, then most negative
  
  # LEAST NEGATIVE ABSOLUTE
  # without pinned posts
  df_sort23 <- comment_data_8 %>% group_by(article) %>% 
    arrange(article, desc(order_roots), order) # least negative
  
  # with pinned posts
  df_sort24 <- comment_data_9 %>% group_by(article) %>%
    arrange(article, desc(order_roots), order) # pinned, then least negative

```

##III. Replies separately
```{r}
# calculates sorting policies with loose replies for 1 discussion
  # comment_data_1 is the dataset for 1 discussion
  # returns df_sort_list_rl

  # CHRONOLOGICAL
  # without pinned posts
  df_sort25 <- comment_data_1 %>% group_by(article) %>% 
    arrange(article, timestamp_f) # chronological
  
  # with pinned posts
  df_sort26 <- comment_data_1 %>% group_by(article) %>%
    arrange(article, desc(pinned_f), timestamp_f) # pinned, then chronological
  
  # REVERSE CHRONOLOGICAL
  # without pinned posts
  df_sort27 <- comment_data_1 %>% group_by(article) %>% 
    arrange(article, desc(timestamp_f)) # reverse chronological
  
  # with pinned posts
  df_sort28 <- comment_data_1 %>% group_by(article) %>%
    arrange(article, desc(pinned_f), desc(timestamp_f)) # pinned, then reverse chronological
  
  # MOST POSITIVE ABSOLUTE
  # without pinned posts
  df_sort29 <- comment_data_1 %>% group_by(article) %>% 
    arrange(article, desc(votes_pos)) # most positive
  
  # with pinned posts
  df_sort30 <- comment_data_1 %>% group_by(article) %>%
    arrange(article, desc(pinned_f), desc(votes_pos)) # pinned, then most positive
  
  # MOST POSITIVE RELATIVE
  # without pinned posts
  df_sort31 <- comment_data_1 %>% group_by(article) %>% 
    arrange(article, desc(votes_rel)) # most positive
  
  # with pinned posts
  df_sort32 <- comment_data_1 %>% group_by(article) %>%
    arrange(article, desc(pinned_f), desc(votes_rel)) # pinned, then most positive
  
  # MOST NEGATIVE ABSOLUTE
  # without pinned posts
  df_sort33 <- comment_data_1 %>% group_by(article) %>% 
    arrange(article, desc(votes_neg)) # most negative
  
  # with pinned posts
  df_sort34 <- comment_data_1 %>% group_by(article) %>%
    arrange(article, desc(pinned_f), desc(votes_neg)) # pinned, then most negative
  
  # LEAST NEGATIVE ABSOLUTE
  # without pinned posts
  df_sort35 <- comment_data_1 %>% group_by(article) %>% 
    arrange(article, votes_neg) # least negative
  
  # with pinned posts
  df_sort36 <- comment_data_1 %>% group_by(article) %>%
    arrange(article, desc(pinned_f), votes_neg) # pinned, then least negative
  

```

##Sum up sorting policies
```{r}
df_sort_list_rh <- list(# hidden replies
                     df_sort1, df_sort2, df_sort3, df_sort4, df_sort5, df_sort6, df_sort7, df_sort8, 
                     df_sort9, df_sort10, df_sort11, df_sort12)

df_sort_list_rt <- list( # reply trees
                     df_sort13, df_sort14, df_sort15, df_sort16, df_sort17, df_sort18, df_sort19,
                     df_sort20, df_sort21, df_sort22, df_sort23, df_sort24)

df_sort_list_rl <- list( # replies loose
                     df_sort25, df_sort26, df_sort27, df_sort28, df_sort29, df_sort30, df_sort31,
                     df_sort32, df_sort33, df_sort34, df_sort35, df_sort36)

sorting_policies <- c("chron", "chron_pinned", "rev-chron", "rev-chron_pinned", "pos-abs", "pos-abs_pinned", "pos-rel", "pos-rel_pinned",  "neg-abs", "neg-abs_pinned",  "least-neg-abs", "least-neg-abs_pinned")

sorting_policies_rh <- paste0(sorting_policies, "_", "rh")
sorting_policies_rt <- paste0(sorting_policies, "_", "rt")
sorting_policies_rl <- paste0(sorting_policies, "_", "rl")

df_sort_list <- c(df_sort_list_rh, df_sort_list_rt, df_sort_list_rl)
# unlist df_sort_list
#df_sort_list_flat <- unlist(df_sort_list, recursive=FALSE)

df_sort_list_flat <- unlist(df_sort_list)
sorting_policies_list <- c(sorting_policies_rh, sorting_policies_rt, sorting_policies_rl)
sorting_policies_list_flat <- unlist(sorting_policies_list)

```

#Graphs

##Graph functions - 1 discussion
```{r}

# SMOG readability
prop_SMOG <- function(df_sort_list, sorting_policies){
  
  # proportion of discussion read
  df_plot <- data.frame(n = 1:nrow(df_sort_list[[36]]))
  
  for(i in df_sort_list){
    
    # offset readability score to make all positive
    if(as.numeric(summary(i$SMOG_readability)[1]) < 0){
      i$SMOG_readability_pos <- i$SMOG_readability - as.numeric(summary(i$SMOG_readability)[1])
    } else {
      i$SMOG_readability_pos <- i$SMOG_readability
    }
    
    # replace NAs with zeros
    i$SMOG_readability_pos <- ifelse(is.na(i$SMOG_readability_pos)==TRUE, 0, i$SMOG_readability_pos)
                                     
    # get cumulative sum of proportion
    cum_sum <- cumsum(i$SMOG_readability_pos)
    
    if(length(cum_sum) == 4680){
      
      # add to article dataframe
      df_plot <- cbind(df_plot, cum_sum)
      
    } else {
      
      num_NAs <- 4680 - length(cum_sum)
      na_vector <- rep(NA, num_NAs)
      
      cum_sum_add <- c(cum_sum, na_vector)
      
      # add to article dataframe
      df_plot <- cbind(df_plot, cum_sum_add)
      
    }
  }
  
  colnames(df_plot) <- c("n", sorting_policies)
  
  df_plot_long <- df_plot %>% pivot_longer(cols = sorting_policies[1]:sorting_policies[36],
                                           names_to = "sorting_policy",
                                           values_to = "values")
  return(df_plot_long)
}

df_plot_SMOG <- prop_SMOG(df_sort_list, sorting_policies_list)

View(df_plot_SMOG)







####################################################################
# OLD FUNCTIONS: proportion of top X comments
####################################################################


# Relevance (cosine similarity to article)
top_10p_cosine1 <- function(df_sort_list, sorting_policies){
  
  # proportion of discussion read
  df_sort_list[[1]]$n_rel <- 1/nrow(df_sort_list[[1]])
  
  df_plot <- data.frame(cumsum(df_sort_list[[1]]$n_rel))
  for(i in df_sort_list){
    top_10p_x1 <- i %>% arrange(desc(cosine_1))
    top_10p_x1 <- top_10p_x1$comment_id[1:as.integer(round((0.1*nrow(i)), 0))]
    i$top10p_x <- ifelse(i$comment_id %in% top_10p_x1, 1, 0)
    i$top10p_x <- i$top10p_x/sum(i$top10p_x)
    
    df_plot <- cbind(df_plot, cumsum(i$top10p_x))
  }
  colnames(df_plot) <- c("n_rel", sorting_policies)
  
  df_plot_long <- df_plot %>% pivot_longer(cols = sorting_policies[1]:sorting_policies[12],
                                           names_to = "sorting_policy",
                                           values_to = "values")
  return(df_plot_long)
}


# Lexical diversity
top_10p_lexdiv <- function(df_sort_list, sorting_policies){
  
  # proportion of discussion read
  df_sort_list[[1]]$n_rel <- 1/nrow(df_sort_list[[1]])
  df_plot <- data.frame(cumsum(df_sort_list[[1]]$n_rel))
  for(i in df_sort_list){
    top_10p_x1 <- i %>% arrange(desc(lexdiv_cttr))
    top_10p_x1 <- top_10p_x1$comment_id[1:as.integer(round((0.1*nrow(i)), 0))]
    i$top10p_x <- ifelse(i$comment_id %in% top_10p_x1, 1, 0)
    i$top10p_x <- i$top10p_x/sum(i$top10p_x)
    
    df_plot <- cbind(df_plot, cumsum(i$top10p_x))
  }
  colnames(df_plot) <- c("n_rel", sorting_policies)
  
  df_plot_long <- df_plot %>% pivot_longer(cols = sorting_policies[1]:sorting_policies[12],
                                           names_to = "sorting_policy",
                                           values_to = "values")
  return(df_plot_long)
}


```

##Final graph function
```{r, fig.height=5, fig.width=6}
# SMOG readability sortings for a given article
prop_SMOG <- function(df_sort_list_flat, sorting_policies = sorting_policies_list_flat){
  
  # create dataframe for given article
  #df_article_scores <- data.frame(sorting_policies = sorting_policies_list_flat, mean_score = vector("numeric", 36))
  
  i <- df_sort_list_flat[[36]]
  
  prop_disc <- rep(1/nrow(i), nrow(i))
  cum_sum_prop_disc <- cumsum(prop_disc)
    
  
  df_graph <- data.frame(prop_disc = cum_sum_prop_disc)
  
  
    
  # loop through all 36 sorting policies
  for(j in 13:length(df_sort_list_flat)){
    
    # get dataframe with sorting
    i <- df_sort_list_flat[[j]]
    
    # PERCENTAGE OF SCORE
    
    # offset readability score to make all positive
    if(as.numeric(summary(i$SMOG_readability)[1]) < 0){
      i$SMOG_readability_pos <- i$SMOG_readability - as.numeric(summary(i$SMOG_readability)[1])
    } else {
      i$SMOG_readability_pos <- i$SMOG_readability
    }
    
    # replace NAs with zeros
    i$SMOG_readability_pos <- ifelse(is.na(i$SMOG_readability_pos)==TRUE, 0, i$SMOG_readability_pos)
                                     
    # calculate proportion of readability score read
    i$SMOG_prop <- i$SMOG_readability_pos/sum(i$SMOG_readability_pos)
    
    # get cumulative sum of proportion
    cum_sum_prop <- cumsum(i$SMOG_prop)
    
    # PERCENTAGE OF DISCUSSION
    
    prop_disc <- rep(1/nrow(i), nrow(i))
    cum_sum_prop_disc <- cumsum(prop_disc)
    
    # NORMAL GRAPH
    df_graph <- cbind(df_graph, cum_sum_prop)
  
    
    # DETRENDED GRAPH
    
    #df_graph$prop_score_detrend <- df_graph$prop_score - df_graph$prop_disc
    
    #df_article_scores[j,2] <- mean(df_graph$prop_score_detrend)

  }
  
  colnames(df_graph) <- c("n_prop", sorting_policies_list_flat[13:36])

  return(df_graph)
}

df_plot_SMOG <- prop_SMOG(df_sort_list)

df_plot_SMOG_long <- df_plot_SMOG %>% pivot_longer(cols = 2:25, names_to = "policy", values_to = "SMOG_readability")

p <- ggplot(df_plot_SMOG_long, aes(x=n_prop, y = SMOG_readability)) +
    geom_line(aes(colour = policy), size = 0.8, alpha = 0.5) +
    labs(title = "Sorting of most readable comments by policy") +
    theme_minimal() +
    theme(panel.grid = element_blank(),
          panel.border = element_rect(color = "black", fill = NA, size = 0.1),
          legend.position = "none"
          ) +
    scale_color_manual(values=user_palette) +
      xlab("proportion of debate read") +
    ylab("proportion readability score read") +
    xlim(0,1) + ylim(0,1)
  
print(p)

```

# detrended
```{r}
# SMOG readability sortings for a given article
prop_SMOG_det <- function(df_sort_list_flat, sorting_policies = sorting_policies_list_flat){
  
  # create dataframe for given article
  #df_article_scores <- data.frame(sorting_policies = sorting_policies_list_flat, mean_score = vector("numeric", 36))
  
  i <- df_sort_list_flat[[36]]
  
  prop_disc <- rep(1/nrow(i), nrow(i))
  cum_sum_prop_disc <- cumsum(prop_disc)
    
  
  df_graph <- data.frame(prop_disc = cum_sum_prop_disc)
  
  
    
  # loop through all 36 sorting policies
  for(j in 13:length(df_sort_list_flat)){
    
    # get dataframe with sorting
    i <- df_sort_list_flat[[j]]
    
    # PERCENTAGE OF SCORE
    
    # offset readability score to make all positive
    if(as.numeric(summary(i$SMOG_readability)[1]) < 0){
      i$SMOG_readability_pos <- i$SMOG_readability - as.numeric(summary(i$SMOG_readability)[1])
    } else {
      i$SMOG_readability_pos <- i$SMOG_readability
    }
    
    # replace NAs with zeros
    i$SMOG_readability_pos <- ifelse(is.na(i$SMOG_readability_pos)==TRUE, 0, i$SMOG_readability_pos)
                                     
    # calculate proportion of readability score read
    i$SMOG_prop <- i$SMOG_readability_pos/sum(i$SMOG_readability_pos)
    
    # get cumulative sum of proportion
    cum_sum_prop <- cumsum(i$SMOG_prop)
    
    # PERCENTAGE OF DISCUSSION
    
    prop_disc <- rep(1/nrow(i), nrow(i))
    cum_sum_prop_disc <- cumsum(prop_disc)
    
    # NORMAL GRAPH
    df_graph <- cbind(df_graph, cum_sum_prop)
  
    
    # DETRENDED GRAPH
    
    df_graph$prop_score_detrend <- df_graph$prop_score - df_graph$prop_disc
    
    #df_article_scores[j,2] <- mean(df_graph$prop_score_detrend)

  }
  
  colnames(df_graph) <- c("n_prop", sorting_policies_list_flat[13:36])

  return(df_graph)
}

df_plot_SMOG_det <- prop_SMOG_det(df_sort_list)

df_plot_SMOG_long$SMOG_readability_detrended <- df_plot_SMOG_long$SMOG_readability - df_plot_SMOG_long$n_prop

user_palette <- rep(c("#004949","#ff6db6","#490092", 
                      "#6db6ff","#db6d00","#24ff24"), each=4)

p <- ggplot(df_plot_SMOG_long, aes(x=n_prop, y = SMOG_readability_detrended)) +
    geom_line(aes(colour = policy), size = 0.8, alpha = 0.5) +
    labs(title = "Sorting of most readable comments by policy") +
    theme_minimal() +
    theme(panel.grid = element_blank(),
          panel.border = element_rect(color = "black", fill = NA, size = 0.1),
          legend.position = "none"
          ) +
    scale_color_manual(values=user_palette) +
    xlab("proportion of debate read") +
    ylab("detrended proportion of readability score read") 
    #xlim(0,1) + ylim(0,1)
  
print(p)
```



##Plot graphs - 1 discussion
```{r, fig.height=4, fig.width=6}

replies_palette <- rep(c("#E69F00", "#56B4E9", "#ff6db6"), 12)
pinned_palette <- rep(c("#E69F00", "#56B4E9"), each = 3, 6)
user_palette <- rep(c("#004949","#ff6db6","#490092", 
                      "#6db6ff","#db6d00","#24ff24"), each=6)




c("#004949","#009292","#ff6db6","#ffb6db", "#490092","#006ddb",
                      "#b66dff","#6db6ff","#b6dbff","#920000","#924900","#db6d00","#24ff24","#ffff6d")

for(i in list(replies_palette, pinned_palette, user_palette)){
  
  p <- ggplot(df_plot_SMOG, aes(x=n, y = values)) +
    geom_line(aes(colour = sorting_policy), size = 0.8, alpha = 0.5) +
    labs(title = "Sorting of most readable comments by sorting policy") +
    xlab("number of comments read") +
    ylab("readability score read") +
    theme_minimal() +
    theme(panel.grid = element_blank(),
          panel.border = element_rect(color = "black", fill = NA, size = 0.1)
          #,legend.position = "none"
          ) +
    scale_color_manual(values=i) +
    xlim(0,20) + ylim(0,200)
  
  print(p)
  
}

unique(df_plot_SMOG$sorting_policy)

#OLD:

for(i in 1:3){
  
  df_plot <- top_10p_cosine1(df_sort_list[[i]], sorting_policies_list[[i]])
  p <- ggplot(df_plot, aes(x=n, y = values)) +
    geom_line(aes(colour = sorting_policy), size = 0.8, alpha = 0.5) +
    labs(title = "Sorting of most relevant comments by sorting policy", subtitle = "Discussion of article 3177 with 4675 comments, Cosine similarity to article") +
    xlab("n/N proportion of comments read") +
    ylab("proportion of overall 10% most relevant comments") +
    theme_minimal() +
    theme(panel.grid = element_blank(),
          panel.border = element_rect(color = "black", fill = NA, size = 0.1)) +
    xlim(0, 1) + ylim(0, 1)
  
  print(p)
}

for(i in 1:3){
  df_plot <- top_10p_lexdiv(df_sort_list[[i]], sorting_policies_list[[i]])
  
  p <- ggplot(df_plot, aes(x=n_rel, y = values)) +
    geom_line(aes(colour = sorting_policy), size = 0.8, alpha = 0.5) +
    labs(title = "Sorting of most lexically diverse comments by sorting policy", subtitle = "Discussion of article 3177 with 4675 comments") +
    xlab("n/N proportion of comments read") +
    ylab("proportion of overall 10% most diverse comments") +
    theme_minimal() +
    theme(panel.grid = element_blank(),
          panel.border = element_rect(color = "black", fill = NA, size = 0.1)) +
    xlim(0, 1) + ylim(0, 1)
  print(p)
}

```

##Plot detrended graphs - 1 discussion 
```{r}
df_plot_SMOG$values_detrend <- df_plot_SMOG$values - df_plot_SMOG$n

p <- ggplot(df_plot_SMOG, aes(x=n, y = values_detrend)) +
    geom_line(aes(colour = sorting_policy), size = 0.8, alpha = 0.5) +
    labs(title = "Sorting of most lexically diverse comments by sorting policy", subtitle = "Discussion of article 3177 with 4675 comments") +
    xlab("n/N proportion of comments read") +
    ylab("proportion of most diverse comments - n/N") +
    theme_minimal() +
    theme(panel.grid = element_blank(),
          panel.border = element_rect(color = "black", fill = NA, size = 0.1)) 
print(p)

```



#GENERALISED

##Sorting policies 

###I. Replies hidden
```{r}
comment_data_1 <- comment_data_general_subset

View(comment_data_1)


sort_pols_rh <- function(comment_data_1){
  # calculates replies-hidden sorting policies for 1 discussion
  # comment_data_1 is the dataset for 1 discussion
  # returns df_sort_list_rh
  
  # CHRONOLOGICAL
  # without pinned posts
  df_sort1 <- comment_data_1 %>% group_by(article) %>% 
    filter(is_root_comment == 1) %>% # hidden replies
    arrange(article, timestamp_f) # chronological
  
  # with pinned posts
  df_sort2 <- comment_data_1 %>% group_by(article) %>%
    filter(is_root_comment == 1) %>% # hidden replies
    arrange(article, desc(pinned_f), timestamp_f) # pinned, then chronological
  
  # REVERSE CHRONOLOGICAL
  # without pinned posts
  df_sort3 <- comment_data_1 %>% group_by(article) %>% 
    filter(is_root_comment == 1) %>% # hidden replies
    arrange(article, desc(timestamp_f)) # reverse chronological
  
  # with pinned posts
  df_sort4 <- comment_data_1 %>% group_by(article) %>%
    filter(is_root_comment == 1) %>% # hidden replies
    arrange(article, desc(pinned_f), desc(timestamp_f)) # pinned, then reverse chronological
  
  # MOST POSITIVE ABSOLUTE
  # without pinned posts
  df_sort5 <- comment_data_1 %>% group_by(article) %>% 
    filter(is_root_comment == 1) %>% # hidden replies
    arrange(article, desc(votes_pos)) # most positive
  
  # with pinned posts
  df_sort6 <- comment_data_1 %>% group_by(article) %>%
    filter(is_root_comment == 1) %>% # hidden replies
    arrange(article, desc(pinned_f), desc(votes_pos)) # pinned, then most positive
  
  # MOST POSITIVE RELATIVE
  # without pinned posts
  df_sort7 <- comment_data_1 %>% group_by(article) %>% 
    filter(is_root_comment == 1) %>% # hidden replies
    arrange(article, desc(votes_rel)) # most positive
  
  # with pinned posts
  df_sort8 <- comment_data_1 %>% group_by(article) %>%
    filter(is_root_comment == 1) %>% # hidden replies
    arrange(article, desc(pinned_f), desc(votes_rel)) # pinned, then most positive
  
  # MOST NEGATIVE ABSOLUTE
  # without pinned posts
  df_sort9 <- comment_data_1 %>% group_by(article) %>% 
    filter(is_root_comment == 1) %>% # hidden replies
    arrange(article, desc(votes_neg)) # most negative
  
  # with pinned posts
  df_sort10 <- comment_data_1 %>% group_by(article) %>%
    filter(is_root_comment == 1) %>% # hidden replies
    arrange(article, desc(pinned_f), desc(votes_neg)) # pinned, then most negative
  
  # LEAST NEGATIVE ABSOLUTE
  # without pinned posts
  df_sort11 <- comment_data_1 %>% group_by(article) %>% 
    filter(is_root_comment == 1) %>% # hidden replies
    arrange(article, votes_neg) # least negative
  
  # with pinned posts
  df_sort12 <- comment_data_1 %>% group_by(article) %>%
    filter(is_root_comment == 1) %>% # hidden replies
    arrange(article, desc(pinned_f), votes_neg) # pinned, then least negative
  
  df_sort_list_rh <- list(# hidden replies
                     df_sort1, df_sort2, df_sort3, df_sort4, df_sort5, df_sort6, df_sort7, df_sort8, 
                     df_sort9, df_sort10, df_sort11, df_sort12)
  
  return(df_sort_list_rh)
}

```

###II. Replies shown in tree
```{r}
sort_pols_rt <- function(comment_data_1){
  # calculates reply-tree sorting policies for 1 discussion
  # comment_data_1 is the dataset for 1 discussion
  # returns df_sort_list_rt
  # arrange only roots chronologically but show replies beneath
  
  # get CHRONOLOGICAL order of root posts only
  root_order <- comment_data_1 %>% filter(is_root_comment==1) %>% arrange(timestamp_f) %>% select(root_of_tree)
  root_order$order_roots <- 1:nrow(root_order)
  comment_data_2 <- merge(comment_data_1, root_order, by = "root_of_tree", all.x=TRUE, sort = FALSE)
  
  # get CHRONOLOGICAL order of root posts only WITH PINNED
  root_order <- comment_data_1 %>% filter(is_root_comment==1) %>% arrange(pinned_f, timestamp_f) %>% select(root_of_tree)
  root_order$order_roots <- 1:nrow(root_order)
  comment_data_3 <- merge(comment_data_1, root_order, by = "root_of_tree", all.x=TRUE, sort = FALSE)

  # CHRONOLOGICAL
  # without pinned posts
  df_sort13 <- comment_data_2 %>% group_by(article) %>% 
    arrange(article, order_roots, order) # chronological
  
  # with pinned posts
  df_sort14 <- comment_data_3 %>% group_by(article) %>%
    arrange(article, order_roots, order) # pinned, then chronological
  
  # REVERSE CHRONOLOGICAL
  # without pinned posts
  df_sort15 <- comment_data_2 %>% group_by(article) %>%  
    arrange(article, desc(order_roots), order) # rev chronological
  
  # with pinned posts
  df_sort16 <- comment_data_3 %>% group_by(article) %>%  
    arrange(article, desc(order_roots), order) # pinned, then rev chronological

  
  # get VOTES_POS order of root posts only (high to low)
  root_order <- comment_data_1 %>% filter(is_root_comment==1) %>% arrange(desc(votes_pos)) %>% select(root_of_tree)
  root_order$order_roots <- 1:nrow(root_order)
  comment_data_4 <- merge(comment_data_1, root_order, by = "root_of_tree", all.x=TRUE, sort = FALSE)
  
  # get VOTES_POS order of root posts only WITH PINNED (high to low)
  root_order <- comment_data_1 %>% filter(is_root_comment==1) %>% arrange(pinned_f, desc(votes_pos)) %>% select(root_of_tree)
  root_order$order_roots <- 1:nrow(root_order)
  comment_data_5 <- merge(comment_data_1, root_order, by = "root_of_tree", all.x=TRUE, sort = FALSE)
  
  # MOST POSITIVE ABSOLUTE
  # without pinned posts
  df_sort17 <- comment_data_4 %>% group_by(article) %>% 
    arrange(article, order_roots, order) # most positive roots
  
  # with pinned posts
  df_sort18 <- comment_data_5 %>% group_by(article) %>%
    arrange(article, order_roots, order) # pinned, then most positive roots, then replies
  
  
  
  
  # get VOTES_REL order of root posts only (high to low)
  root_order <- comment_data_1 %>% filter(is_root_comment==1) %>% arrange(desc(votes_rel)) %>% select(root_of_tree)
  root_order$order_roots <- 1:nrow(root_order)
  comment_data_6 <- merge(comment_data_1, root_order, by = "root_of_tree", all.x=TRUE, sort = FALSE)
  
  # get VOTES_REL order of root posts only WITH PINNED (high to low)
  root_order <- comment_data_1 %>% filter(is_root_comment==1) %>% arrange(pinned_f, desc(votes_rel)) %>% select(root_of_tree)
  root_order$order_roots <- 1:nrow(root_order)
  comment_data_7 <- merge(comment_data_1, root_order, by = "root_of_tree", all.x=TRUE, sort = FALSE)
  
  # MOST POSITIVE RELATIVE
  # without pinned posts
  df_sort19 <- comment_data_6 %>% group_by(article) %>% 
    arrange(article, order_roots, order) # most positive
  
  # with pinned posts
  df_sort20 <- comment_data_7 %>% group_by(article) %>%
    arrange(article, order_roots, order) # pinned, then most positive
  
  
  
  
  # get VOTES_NEG order of root posts only (high to low)
  root_order <- comment_data_1 %>% filter(is_root_comment==1) %>% arrange(desc(votes_neg)) %>% select(root_of_tree)
  root_order$order_roots <- 1:nrow(root_order)
  comment_data_8 <- merge(comment_data_1, root_order, by = "root_of_tree", all.x=TRUE, sort = FALSE)
  
  # get VOTES_NEG order of root posts only WITH PINNED (high to low)
  root_order <- comment_data_1 %>% filter(is_root_comment==1) %>% arrange(pinned_f, desc(votes_neg)) %>% select(root_of_tree)
  root_order$order_roots <- 1:nrow(root_order)
  comment_data_9 <- merge(comment_data_1, root_order, by = "root_of_tree", all.x=TRUE, sort = FALSE)
  
  # MOST NEGATIVE ABSOLUTE
  # without pinned posts
  df_sort21 <- comment_data_8 %>% group_by(article) %>% 
    arrange(article, order_roots, order) # most negative roots, then replies
  
  # with pinned posts
  df_sort22 <- comment_data_9 %>% group_by(article) %>%
    arrange(article, order_roots, order) # pinned, then most negative
  
  # LEAST NEGATIVE ABSOLUTE
  # without pinned posts
  df_sort23 <- comment_data_8 %>% group_by(article) %>% 
    arrange(article, desc(order_roots), order) # least negative
  
  # with pinned posts
  df_sort24 <- comment_data_9 %>% group_by(article) %>%
    arrange(article, desc(order_roots), order) # pinned, then least negative
  
  df_sort_list_rt <- list( # reply trees
                     df_sort13, df_sort14, df_sort15, df_sort16, df_sort17, df_sort18, df_sort19,
                     df_sort20, df_sort21, df_sort22, df_sort23, df_sort24)
  
  return(df_sort_list_rt)
}

```


###III. Replies separately
```{r}

sort_pols_rl <- function(comment_data_1){
  # calculates sorting policies with loose replies for 1 discussion
  # comment_data_1 is the dataset for 1 discussion
  # returns df_sort_list_rl

  # CHRONOLOGICAL
  # without pinned posts
  df_sort25 <- comment_data_1 %>% group_by(article) %>% 
    arrange(article, timestamp_f) # chronological
  
  # with pinned posts
  df_sort26 <- comment_data_1 %>% group_by(article) %>%
    arrange(article, desc(pinned_f), timestamp_f) # pinned, then chronological
  
  # REVERSE CHRONOLOGICAL
  # without pinned posts
  df_sort27 <- comment_data_1 %>% group_by(article) %>% 
    arrange(article, desc(timestamp_f)) # reverse chronological
  
  # with pinned posts
  df_sort28 <- comment_data_1 %>% group_by(article) %>%
    arrange(article, desc(pinned_f), desc(timestamp_f)) # pinned, then reverse chronological
  
  # MOST POSITIVE ABSOLUTE
  # without pinned posts
  df_sort29 <- comment_data_1 %>% group_by(article) %>% 
    arrange(article, desc(votes_pos)) # most positive
  
  # with pinned posts
  df_sort30 <- comment_data_1 %>% group_by(article) %>%
    arrange(article, desc(pinned_f), desc(votes_pos)) # pinned, then most positive
  
  # MOST POSITIVE RELATIVE
  # without pinned posts
  df_sort31 <- comment_data_1 %>% group_by(article) %>% 
    arrange(article, desc(votes_rel)) # most positive
  
  # with pinned posts
  df_sort32 <- comment_data_1 %>% group_by(article) %>%
    arrange(article, desc(pinned_f), desc(votes_rel)) # pinned, then most positive
  
  # MOST NEGATIVE ABSOLUTE
  # without pinned posts
  df_sort33 <- comment_data_1 %>% group_by(article) %>% 
    arrange(article, desc(votes_neg)) # most negative
  
  # with pinned posts
  df_sort34 <- comment_data_1 %>% group_by(article) %>%
    arrange(article, desc(pinned_f), desc(votes_neg)) # pinned, then most negative
  
  # LEAST NEGATIVE ABSOLUTE
  # without pinned posts
  df_sort35 <- comment_data_1 %>% group_by(article) %>% 
    arrange(article, votes_neg) # least negative
  
  # with pinned posts
  df_sort36 <- comment_data_1 %>% group_by(article) %>%
    arrange(article, desc(pinned_f), votes_neg) # pinned, then least negative
  
  df_sort_list_rl <- list( # replies loose
                     df_sort25, df_sort26, df_sort27, df_sort28, df_sort29, df_sort30, df_sort31,
                     df_sort32, df_sort33, df_sort34, df_sort35, df_sort36)
  
  return(df_sort_list_rl)
}

```

###Sum up sorting policies
```{r}
sorting_policies <- c("chron", "chron_pinned", "rev-chron", "rev-chron_pinned", "pos-abs", "pos-abs_pinned", "pos-rel", "pos-rel_pinned",  "neg-abs", "neg-abs_pinned",  "least-neg-abs", "least-neg-abs_pinned")

sorting_policies_rh <- paste0(sorting_policies, "_", "rh")
sorting_policies_rt <- paste0(sorting_policies, "_", "rt")
sorting_policies_rl <- paste0(sorting_policies, "_", "rl")

sorting_policies_list <- list(sorting_policies_rh, sorting_policies_rt, sorting_policies_rl)
# unlist sorting policies list
sorting_policies_list_flat <- unlist(sorting_policies_list)

```

###TEST
```{r}
#subset to test
comment_data_general_subset <- comment_data_general[which(comment_data_general$article== "/story/2000138726456/zwei-milliarden-euro-fuer-wien-energie-wien-segnete-vertrag-mit"),]
nrow(comment_data_general_subset)

# sort subset
df_sort_list_rh <- sort_pols_rh(comment_data_general_subset)
df_sort_list_rt <- sort_pols_rt(comment_data_general_subset)
df_sort_list_rl <- sort_pols_rl(comment_data_general_subset)
df_sort_list <- list(df_sort_list_rh, df_sort_list_rt, df_sort_list_rl)


# unlist df_sort_list
df_sort_list_flat <- unlist(df_sort_list, recursive=FALSE)

```


##Sorting Values 

### x = number of comments, y = proportion of top 10%
```{r}
library(tidyr)
library(ggplot2)
# x-axis = n number of comments in discussion

# SMOG readability sortings for a given article
top_10p_SMOG <- function(df_sort_list_flat, sorting_policies = sorting_policies_list_flat){
  
  # create dataframe for given article
  df_plot_article <- data.frame(1:nrow(df_sort_list_flat[[36]]))
  colnames(df_plot_article) <- c("n")
    
  # loop through all sorting policies
  for(i in df_sort_list_flat){
    
    # sort by highest readability
    top_10p_x1 <- i %>% arrange(desc(SMOG_readability))
    
    # get comment ids of 10% most readable comments
    top_10p_x1 <- top_10p_x1$comment_id[1:as.integer(round((0.1*nrow(i)), 0))]
    
    # dummy variable if top 10% comment 
    i$top10p_x <- ifelse(i$comment_id %in% top_10p_x1, 1, 0)
    
    # calculate proportion of readable comments read
    i$top10p_x <- i$top10p_x/sum(i$top10p_x)
    
    # get cumulative sum of proportion
    cum_sum_top10 <- cumsum(i$top10p_x)
    
    # make length of whole discussion
    if(length(cum_sum_top10) != nrow(df_sort_list_flat[[36]])){ # if vector shorter than discussion
      
      # calculcate by how much
      diff_vector <- nrow(df_sort_list_flat[[36]]) - length(cum_sum_top10)
      
      # add zeros
      na_vector <- rep(0, diff_vector)
      cum_sum_top10 <- c(cum_sum_top10, na_vector)
    }
    
    # add to article dataframe
    df_plot_article <- cbind(df_plot_article, cum_sum_top10)

  }
  
  # rename columns
  colnames(df_plot_article) <- c("n_rel", sorting_policies)

  return(df_plot_article)
}

# test
df_plot_smog_a <- top_10p_SMOG(df_sort_list_flat, sorting_policies_list_flat)




# Relevance (Cosine similarity)
top_10p_cosine1 <- function(df_sort_list_flat, sorting_policies = sorting_policies_list_flat){
  
  # create dataframe for given article
  df_plot_article <- data.frame(1:nrow(df_sort_list_flat[[36]]))
  colnames(df_plot_article) <- c("n")
    
  # loop through all sorting policies
  for(i in df_sort_list_flat){
    
    # sort by highest readability
    top_10p_x1 <- i %>% arrange(desc(cosine_1))
    
    # get comment ids of 10% most readable comments
    top_10p_x1 <- top_10p_x1$comment_id[1:as.integer(round((0.1*nrow(i)), 0))]
    
    # dummy variable if top 10% comment 
    i$top10p_x <- ifelse(i$comment_id %in% top_10p_x1, 1, 0)
    
    # calculate proportion of relevant comments read
    i$top10p_x <- i$top10p_x/sum(i$top10p_x)
    
    # get cumulative sum of proportion
    cum_sum_top10 <- cumsum(i$top10p_x)
    
    # make length of whole discussion
    if(length(cum_sum_top10) != nrow(df_sort_list_flat[[36]])){ # if vector shorter than discussion
      
      # calculcate by how much
      difference <- nrow(df_sort_list_flat[[36]]) - length(cum_sum_top10)
      
      # add zeros
      na_vector <- rep(0, difference)
      cum_sum_top10 <- c(cum_sum_top10, na_vector)
    }
    
    # add to article dataframe
    df_plot_article <- cbind(df_plot_article, cum_sum_top10)

  }
  
  # rename columns
  colnames(df_plot_article) <- c("n_rel", sorting_policies)

  return(df_plot_article)
}

# test
df_plot_cosine1_a <- top_10p_cosine1(df_sort_list_flat, sorting_policies_list_flat)



# Lexical diversity
top_10p_lexdiv <- function(df_sort_list_flat, sorting_policies = sorting_policies_list_flat){
  
  # create dataframe for given article
  df_plot_article <- data.frame(1:nrow(df_sort_list_flat[[36]]))
  colnames(df_plot_article) <- c("n")
    
  # loop through all sorting policies
  for(i in df_sort_list_flat){
    
    # sort by highest lexical diversity
    top_10p_x1 <- i %>% arrange(desc(lexdiv_cttr))
    
    # get comment ids of 10% most readable comments
    top_10p_x1 <- top_10p_x1$comment_id[1:as.integer(round((0.1*nrow(i)), 0))]
    
    # dummy variable if top 10% comment 
    i$top10p_x <- ifelse(i$comment_id %in% top_10p_x1, 1, 0)
    
    # calculate proportion of relevant comments read
    i$top10p_x <- i$top10p_x/sum(i$top10p_x)
    
    # get cumulative sum of proportion
    cum_sum_top10 <- cumsum(i$top10p_x)
    
    # make length of whole discussion
    if(length(cum_sum_top10) != nrow(df_sort_list_flat[[36]])){ # if vector shorter than discussion
      
      # calculcate by how much
      difference <- nrow(df_sort_list_flat[[36]]) - length(cum_sum_top10)
      
      # add zeros
      na_vector <- rep(0, difference)
      cum_sum_top10 <- c(cum_sum_top10, na_vector)
    }
    
    # add to article dataframe
    df_plot_article <- cbind(df_plot_article, cum_sum_top10)

  }
  
  # rename columns
  colnames(df_plot_article) <- c("n_rel", sorting_policies)

  return(df_plot_article)
}

# test
df_plot_lexdiv_a <- top_10p_lexdiv(df_sort_list_flat, sorting_policies_list_flat)
View(df_plot_lexdiv_a)

```

###x = n/N, y = proportion of score
```{r}
library(tidyr)
library(ggplot2)

# SMOG readability sortings for a given article
prop_SMOG <- function(df_sort_list_flat, sorting_policies = sorting_policies_list_flat){
  
  # create dataframe for given article
  df_article_scores <- data.frame(sorting_policies = sorting_policies_list_flat, mean_score = vector("numeric", 36))
    
  # loop through all 36 sorting policies
  for(j in 1:length(df_sort_list_flat)){
    
    # get dataframe with sorting
    i <- df_sort_list_flat[[j]]
    
    # PERCENTAGE OF SCORE
    
    # offset readability score to make all positive
    if(as.numeric(summary(i$SMOG_readability)[1]) < 0){
      i$SMOG_readability_pos <- i$SMOG_readability - as.numeric(summary(i$SMOG_readability)[1])
    } else {
      i$SMOG_readability_pos <- i$SMOG_readability
    }
    
    # replace NAs with zeros
    i$SMOG_readability_pos <- ifelse(is.na(i$SMOG_readability_pos)==TRUE, 0, i$SMOG_readability_pos)
                                     
    # calculate proportion of readability score read
    i$SMOG_prop <- i$SMOG_readability_pos/sum(i$SMOG_readability_pos)
    
    # get cumulative sum of proportion
    cum_sum_prop <- cumsum(i$SMOG_prop)
    
    # PERCENTAGE OF DISCUSSION
    
    prop_disc <- rep(1/nrow(i), nrow(i))
    cum_sum_prop_disc <- cumsum(prop_disc)
    
    # NORMAL GRAPH
    df_graph <- data.frame(prop_disc = cum_sum_prop_disc, prop_score = cum_sum_prop)
    
    # DETRENDED GRAPH
    
    df_graph$prop_score_detrend <- df_graph$prop_score - df_graph$prop_disc
    
    df_article_scores[j,2] <- mean(df_graph$prop_score_detrend)

  }

  return(df_article_scores)
}

# test
#df_smog_scores_a <- prop_SMOG(df_sort_list_flat, sorting_policies_list_flat)



# Relevance (Cosine similarity)
prop_cosine1 <- function(df_sort_list_flat, sorting_policies = sorting_policies_list_flat){
  
  # create dataframe for given article
  df_article_scores <- data.frame(sorting_policies = sorting_policies_list_flat, mean_score = vector("numeric", 36))
    
  # loop through all 36 sorting policies
  for(j in 1:length(df_sort_list_flat)){
    
    # get dataframe with sorting
    i <- df_sort_list_flat[[j]]
    
    # PERCENTAGE OF SCORE
    
    # replace NAs with zero
    i$cosine_1_pos <- ifelse(is.na(i$cosine_1) == TRUE, 0, i$cosine_1)
                                     
    # calculate proportion of cosine score read (if sum larger than 0)
    if(sum(i$cosine_1_pos) == 0){
      i$cosine1_prop <- 0
    } else {
      i$cosine1_prop <- i$cosine_1_pos/sum(i$cosine_1_pos)
    }
    
    # get cumulative sum of proportion
    cum_sum_prop <- cumsum(i$cosine1_prop)
    
    # PERCENTAGE OF DISCUSSION
    
    prop_disc <- rep(1/nrow(i), nrow(i))
    cum_sum_prop_disc <- cumsum(prop_disc)
    
    # NORMAL GRAPH
    df_graph <- data.frame(prop_disc = cum_sum_prop_disc, prop_score = cum_sum_prop)
    
    # DETRENDED GRAPH
    
    df_graph$prop_score_detrend <- df_graph$prop_score - df_graph$prop_disc
    
    df_article_scores[j,2] <- mean(df_graph$prop_score_detrend)

  }

  return(df_article_scores)
} 

# test
#df_cosine1_scores_a <- prop_cosine1(df_sort_list_flat, sorting_policies_list_flat)



# Lexical diversity
prop_lexdiv <- function(df_sort_list_flat, sorting_policies = sorting_policies_list_flat){
  
  # create dataframe for given article
  df_article_scores <- data.frame(sorting_policies = sorting_policies_list_flat, mean_score = vector("numeric", 36))
  
    
  # loop through all 36 sorting policies
  for(j in 1:length(df_sort_list_flat)){
    
    # get dataframe with sorting
    i <- df_sort_list_flat[[j]]
    
    # PERCENTAGE OF SCORE
    
    # offset readability score to make all positive
    if(as.numeric(summary(i$lexdiv_cttr)[1]) < 0){
      i$lexdiv_pos <- i$lexdiv_cttr - as.numeric(summary(i$lexdiv_cttr)[1])
    } else {
      i$lexdiv_pos <- i$lexdiv_cttr
    }
    
    # replace NAs with zeros
    i$lexdiv_pos <- ifelse(is.na(i$lexdiv_pos)==TRUE, 0, i$lexdiv_pos)
                                     
    # calculate proportion of readability score read
    i$lexdiv_prop <- i$lexdiv_pos/sum(i$lexdiv_pos)
    
    # get cumulative sum of proportion
    cum_sum_prop <- cumsum(i$lexdiv_prop)
    
    # PERCENTAGE OF DISCUSSION
    
    prop_disc <- rep(1/nrow(i), nrow(i))
    cum_sum_prop_disc <- cumsum(prop_disc)
    
    # NORMAL GRAPH
    df_graph <- data.frame(prop_disc = cum_sum_prop_disc, prop_score = cum_sum_prop)
    
    # DETRENDED GRAPH
    
    df_graph$prop_score_detrend <- df_graph$prop_score - df_graph$prop_disc
    
    df_article_scores[j,2] <- mean(df_graph$prop_score_detrend)

  }

  return(df_article_scores)
}

# test
#df_lexdiv_scores_a <- prop_lexdiv(df_sort_list_flat, sorting_policies_list_flat)



# Sentiment Positive
prop_sentpos <- function(df_sort_list_flat, sorting_policies = sorting_policies_list_flat){
  
  # create dataframe for given article
  df_article_scores <- data.frame(sorting_policies = sorting_policies_list_flat, mean_score = vector("numeric", 36))
    
  # loop through all 36 sorting policies
  for(j in 1:length(df_sort_list_flat)){
    
    # get dataframe with sorting
    i <- df_sort_list_flat[[j]]
    
    # PERCENTAGE OF SCORE
    
    # replace NAs with zeros
    i$sentiment_prob_pos <- ifelse(is.na(i$sentiment_prob_pos)==TRUE, 0, i$sentiment_prob_pos)
                                     
    # calculate proportion of readability score read
    i$sentpos_prop <- i$sentiment_prob_pos/sum(i$sentiment_prob_pos)
    
    # get cumulative sum of proportion
    cum_sum_prop <- cumsum(i$sentpos_prop)
    
    # PERCENTAGE OF DISCUSSION
    
    prop_disc <- rep(1/nrow(i), nrow(i))
    cum_sum_prop_disc <- cumsum(prop_disc)
    
    # NORMAL GRAPH
    df_graph <- data.frame(prop_disc = cum_sum_prop_disc, prop_score = cum_sum_prop)
    
    # DETRENDED GRAPH
    
    df_graph$prop_score_detrend <- df_graph$prop_score - df_graph$prop_disc
    
    df_article_scores[j,2] <- mean(df_graph$prop_score_detrend)

  }

  return(df_article_scores)
}

# test
#df_sentpos_scores_a <- prop_sentpos(df_sort_list_flat, sorting_policies_list_flat)




# Sentiment Neutral
prop_sentneu <- function(df_sort_list_flat, sorting_policies = sorting_policies_list_flat){
  
  # create dataframe for given article
  df_article_scores <- data.frame(sorting_policies = sorting_policies_list_flat, mean_score = vector("numeric", 36))
    
  # loop through all 36 sorting policies
  for(j in 1:length(df_sort_list_flat)){
    
    # get dataframe with sorting
    i <- df_sort_list_flat[[j]]
    
    # PERCENTAGE OF SCORE
    
    # replace NAs with zeros
    i$sentiment_prob_neu <- ifelse(is.na(i$sentiment_prob_neu)==TRUE, 0, i$sentiment_prob_neu)
                                     
    # calculate proportion of readability score read
    i$sentneu_prop <- i$sentiment_prob_neu/sum(i$sentiment_prob_neu)
    
    # get cumulative sum of proportion
    cum_sum_prop <- cumsum(i$sentneu_prop)
    
    # PERCENTAGE OF DISCUSSION
    
    prop_disc <- rep(1/nrow(i), nrow(i))
    cum_sum_prop_disc <- cumsum(prop_disc)
    
    # NORMAL GRAPH
    df_graph <- data.frame(prop_disc = cum_sum_prop_disc, prop_score = cum_sum_prop)
    
    # DETRENDED GRAPH
    
    df_graph$prop_score_detrend <- df_graph$prop_score - df_graph$prop_disc
    
    df_article_scores[j,2] <- mean(df_graph$prop_score_detrend)

  }

  return(df_article_scores)
}

# test
#df_sentneu_scores_a <- prop_sentneu(df_sort_list_flat, sorting_policies_list_flat)




# Sentiment Negative
prop_sentneg <- function(df_sort_list_flat, sorting_policies = sorting_policies_list_flat){
  
  # create dataframe for given article
  df_article_scores <- data.frame(sorting_policies = sorting_policies_list_flat, mean_score = vector("numeric", 36))
    
  # loop through all 36 sorting policies
  for(j in 1:length(df_sort_list_flat)){
    
    # get dataframe with sorting
    i <- df_sort_list_flat[[j]]
    
    # PERCENTAGE OF SCORE
    
    # replace NAs with zeros
    i$sentiment_prob_neg <- ifelse(is.na(i$sentiment_prob_neg)==TRUE, 0, i$sentiment_prob_neg)
                                     
    # calculate proportion of readability score read
    i$sentneg_prop <- i$sentiment_prob_neg/sum(i$sentiment_prob_neg)
    
    # get cumulative sum of proportion
    cum_sum_prop <- cumsum(i$sentneg_prop)
    
    # PERCENTAGE OF DISCUSSION
    
    prop_disc <- rep(1/nrow(i), nrow(i))
    cum_sum_prop_disc <- cumsum(prop_disc)
    
    # NORMAL GRAPH
    df_graph <- data.frame(prop_disc = cum_sum_prop_disc, prop_score = cum_sum_prop)
    
    # DETRENDED GRAPH
    
    df_graph$prop_score_detrend <- df_graph$prop_score - df_graph$prop_disc
    
    df_article_scores[j,2] <- mean(df_graph$prop_score_detrend)

  }

  return(df_article_scores)
}

# test
#df_sentneg_scores_a <- prop_sentneg(df_sort_list_flat, sorting_policies_list_flat)

```



#Average over all articles - x = number of articles
```{r}
# create lists to store value dataframes of each article
df_plot_smog_list <- list()
df_plot_lexdiv_list <- list()
df_plot_rel_list <- list()

#a <- unique(comment_info_general$article)[50]

# for each article
for(a in unique(comment_info_general$article)[1:100]){ # loop through comment_info to avoid articles with 0 comments
  
  print(a)
  
  # get feature dataframe
  comment_data_a <- get_feature_df(a)
  
  # sort dataframe by 36 sorting policies
  df_sort_list_rh <- sort_pols_rh(comment_data_a) # only root comments (16)
  df_sort_list_rt <- sort_pols_rt(comment_data_a) # all comments (94)
  df_sort_list_rl <- sort_pols_rl(comment_data_a) # all comments (94)
  df_sort_list_flat <- c(df_sort_list_rh, df_sort_list_rt, df_sort_list_rl)
  
  # get dataframe with all sorting values as columns
  df_plot_smog_a <- top_10p_SMOG(df_sort_list_flat, sorting_policies_list_flat)
  df_plot_cosine1_a <- top_10p_cosine1(df_sort_list_flat, sorting_policies_list_flat)
  df_plot_lexdiv_a <- top_10p_lexdiv(df_sort_list_flat, sorting_policies_list_flat)
  
  # fill in zeros to reach 5000 comments
  num_missing <- 5000 - nrow(df_plot_smog_a)
  fill_df <- data.frame(df_plot_smog_a)
  colnames(fill_df) <- gsub("\\.", "-", colnames(fill_df))
  fill_df <- fill_df[1:num_missing,]
  fill_df[] <- 0
  fill_df$n_rel <- (nrow(df_plot_smog_a)+1) : 5000
  df_plot_smog_a <- rbind(df_plot_smog_a, fill_df)
  df_plot_cosine1_a <- rbind(df_plot_cosine1_a, fill_df)
  df_plot_lexdiv_a <- rbind(df_plot_lexdiv_a, fill_df)
  
  # add dataframe to lists
  df_plot_smog_list <- c(df_plot_smog_list, list(df_plot_smog_a))
  df_plot_rel_list <- c(df_plot_rel_list, list(df_plot_cosine1_a))
  df_plot_lexdiv_list <- c(df_plot_lexdiv_list, list(df_plot_lexdiv_a))
}

length(df_plot_smog_list)
length(df_plot_rel_list)
length(df_plot_lexdiv_list)


#df_plot_x_list <- df_plot_smog_list

# for a df_plot_list, get average and pivot longer
get_df_plot <- function(df_plot_x_list){
  
  # Initialize dataframe with first article to store the result
  df_plot_x <- df_plot_x_list[[1]]
  
  # Loop through the dataframes in the list
  for (i in 2:length(df_plot_x_list)) {
    df_plot_x <- df_plot_x + df_plot_x_list[[i]]
  }
  
  # Divide the result by the number of dataframes to get the average
  df_plot_x <- df_plot_x / length(df_plot_x_list)
  
  # pivot long for plotting
  df_plot_x_long <- df_plot_x %>% pivot_longer(cols = all_of(sorting_policies_list_flat),
                                             names_to = "sorting_policy",
                                             values_to = "values")
  }

df_plot_smog <- get_df_plot(df_plot_smog_list)
df_plot_rel <- get_df_plot(df_plot_rel_list)
df_plot_lexdiv <- get_df_plot(df_plot_lexdiv_list)

```


#Average over all articles - x = n/N, y = proportion of score
```{r}
# create dataframes to store values of each article
columns = sorting_policies_list_flat

df_smog <- data.frame(matrix(nrow = 0, ncol = length(columns))) 
df_lexdiv <- data.frame(matrix(nrow = 0, ncol = length(columns))) 
df_cosine1 <- data.frame(matrix(nrow = 0, ncol = length(columns))) 
df_sentpos <- data.frame(matrix(nrow = 0, ncol = length(columns))) 
df_sentneu <- data.frame(matrix(nrow = 0, ncol = length(columns))) 
df_sentneg <- data.frame(matrix(nrow = 0, ncol = length(columns))) 

# name columns after sorting policies
colnames(df_smog) = columns
colnames(df_lexdiv) = columns
colnames(df_cosine1) = columns
colnames(df_sentpos) = columns
colnames(df_sentneu) = columns
colnames(df_sentneg) = columns


# for each article
for(a in unique(comment_data_general$article)){ # loop through comment_info to avoid articles with 0 comments
  
  print(a)
  
  # get subset dataframe
  comment_data_a <- comment_data_general[which(comment_data_general$article == a),]
  
  # sort dataframes by 36 sorting policies
  df_sort_list_rh <- sort_pols_rh(comment_data_a) # only root comments (16)
  df_sort_list_rt <- sort_pols_rt(comment_data_a) # all comments (94)
  df_sort_list_rl <- sort_pols_rl(comment_data_a) # all comments (94)
  df_sort_list_flat <- c(df_sort_list_rh, df_sort_list_rt, df_sort_list_rl)
  
  # get dataframes with average values by sorting policy
  df_smog_a <- prop_SMOG(df_sort_list_flat, sorting_policies_list_flat)
  df_cosine1_a <- prop_cosine1(df_sort_list_flat, sorting_policies_list_flat)
  df_lexdiv_a <- prop_lexdiv(df_sort_list_flat, sorting_policies_list_flat)
  df_sentpos_a <- prop_sentpos(df_sort_list_flat, sorting_policies_list_flat)
  df_sentneu_a <- prop_sentneu(df_sort_list_flat, sorting_policies_list_flat)
  df_sentneg_a <- prop_sentneg(df_sort_list_flat, sorting_policies_list_flat)
  
  # add value column as row to dataframes
  df_smog <- rbind(df_smog, df_smog_a$mean_score)
  df_lexdiv <- rbind(df_lexdiv, df_lexdiv_a$mean_score)
  df_cosine1 <- rbind(df_cosine1, df_cosine1_a$mean_score)
  df_sentpos <- rbind(df_sentpos, df_sentpos_a$mean_score)
  df_sentneu <- rbind(df_sentneu, df_sentneu_a$mean_score)
  df_sentneg <- rbind(df_sentneg, df_sentneg_a$mean_score)
}

# name columns after sorting policies
colnames(df_smog) = columns
colnames(df_lexdiv) = columns
colnames(df_cosine1) = columns
colnames(df_sentpos) = columns
colnames(df_sentneu) = columns
colnames(df_sentneg) = columns

# all 36 policies
df_smog_long <- df_smog %>% pivot_longer(cols = colnames(df_smog), names_to = "sorting_policy", values_to = "SMOG_readability")
df_lexdiv_long <- df_lexdiv %>% pivot_longer(cols = colnames(df_lexdiv), names_to = "sorting_policy", values_to = "lexdiv")
df_cosine1_long <- df_cosine1 %>% pivot_longer(cols = colnames(df_cosine1), names_to = "sorting_policy", values_to = "cosine")
df_sentpos_long <- df_sentpos %>% pivot_longer(cols = colnames(df_sentpos), names_to = "sorting_policy", values_to = "sent_pos")
df_sentneu_long <- df_sentneu %>% pivot_longer(cols = colnames(df_sentneu), names_to = "sorting_policy", values_to = "sent_neu")
df_sentneg_long <- df_sentneg %>% pivot_longer(cols = colnames(df_sentneg), names_to = "sorting_policy", values_to = "sent_neg")



```


```{r}
# by category - user
df_smog_long <- df_avg_user_smog %>% pivot_longer(cols = colnames(df_avg_user_smog), names_to = "sorting_policy", values_to = "SMOG_readability")
df_lexdiv_long <- df_avg_user_lexdiv %>% pivot_longer(cols = colnames(df_avg_user_lexdiv), names_to = "sorting_policy", values_to = "lexdiv")
df_cosine1_long <- df_avg_user_cosine %>% pivot_longer(cols = colnames(df_avg_user_cosine), names_to = "sorting_policy", values_to = "cosine")
df_sentpos_long <- df_avg_user_sentpos %>% pivot_longer(cols = colnames(df_avg_user_sentpos), names_to = "sorting_policy", values_to = "sent_pos")
df_sentneu_long <- df_avg_user_sentneu %>% pivot_longer(cols = colnames(df_avg_user_sentneu), names_to = "sorting_policy", values_to = "sent_neu")
df_sentneg_long <- df_avg_user_sentneg %>% pivot_longer(cols = colnames(df_avg_user_sentneg), names_to = "sorting_policy", values_to = "sent_neg")

# by category - editor
df_smog_long <- df_avg_editor_smog %>% pivot_longer(cols = colnames(df_avg_editor_smog), names_to = "sorting_policy", values_to = "SMOG_readability")
df_lexdiv_long <- df_avg_editor_lexdiv %>% pivot_longer(cols = colnames(df_avg_editor_lexdiv), names_to = "sorting_policy", values_to = "lexdiv")
df_cosine1_long <- df_avg_editor_cosine %>% pivot_longer(cols = colnames(df_avg_editor_cosine), names_to = "sorting_policy", values_to = "cosine")
df_sentpos_long <- df_avg_editor_sentpos %>% pivot_longer(cols = colnames(df_avg_editor_sentpos), names_to = "sorting_policy", values_to = "sent_pos")
df_sentneu_long <- df_avg_editor_sentneu %>% pivot_longer(cols = colnames(df_avg_editor_sentneu), names_to = "sorting_policy", values_to = "sent_neu")
df_sentneg_long <- df_avg_editor_sentneg %>% pivot_longer(cols = colnames(df_avg_editor_sentneg), names_to = "sorting_policy", values_to = "sent_neg")

# by category - structure
df_smog_long <- df_avg_structure_smog %>% pivot_longer(cols = colnames(df_avg_structure_smog), names_to = "sorting_policy", values_to = "SMOG_readability")
df_lexdiv_long <- df_avg_structure_lexdiv %>% pivot_longer(cols = colnames(df_avg_structure_lexdiv), names_to = "sorting_policy", values_to = "lexdiv")
df_cosine1_long <- df_avg_structure_cosine %>% pivot_longer(cols = colnames(df_avg_structure_cosine), names_to = "sorting_policy", values_to = "cosine")
df_sentpos_long <- df_avg_structure_sentpos %>% pivot_longer(cols = colnames(df_avg_structure_sentpos), names_to = "sorting_policy", values_to = "sent_pos")
df_sentneu_long <- df_avg_structure_sentneu %>% pivot_longer(cols = colnames(df_avg_structure_sentneu), names_to = "sorting_policy", values_to = "sent_neu")
df_sentneg_long <- df_avg_structure_sentneg %>% pivot_longer(cols = colnames(df_avg_structure_sentneg), names_to = "sorting_policy", values_to = "sent_neg")
```



##Distribution graphs
```{r, fig.width=10, fig.height=10}

# library
library(ggridges)
library(ggplot2)
library(viridis)
library(hrbrthemes)

# Plot
p_ridge_smog <- ggplot(df_smog_long, aes(x = SMOG_readability, y = sorting_policy, fill = ..x..)) +
  geom_density_ridges_gradient(scale = 3, rel_min_height = 0.01) +
  scale_fill_viridis(option = "C") +
  labs(title = 'Readability score by sorting policy') +
  theme_ipsum() +
    theme(
      legend.position="none",
      panel.spacing = unit(0.1, "lines"),
      strip.text.x = element_text(size = 8),
      plot.title = element_text(size = 12)
    )

p_ridge_lexdiv <- ggplot(df_lexdiv_long, aes(x = lexdiv, y = sorting_policy, fill = ..x..)) +
  geom_density_ridges_gradient(scale = 3, rel_min_height = 0.01) +
  scale_fill_viridis(option = "C") +
  labs(title = 'Lexdiv score by sorting policy') +
  theme_ipsum() +
    theme(
      legend.position="none",
      panel.spacing = unit(0.1, "lines"),
      strip.text.x = element_text(size = 8),
      plot.title = element_text(size = 12)
    )

p_ridge_cosine <- ggplot(df_cosine1_long, aes(x = cosine, y = sorting_policy, fill = ..x..)) +
  geom_density_ridges_gradient(scale = 3, rel_min_height = 0.01) +
  scale_fill_viridis(option = "C") +
  labs(title = 'Cosine score by sorting policy') +
  theme_ipsum() +
    theme(
      legend.position="none",
      panel.spacing = unit(0.1, "lines"),
      strip.text.x = element_text(size = 8),
      plot.title = element_text(size = 12)
    )

p_ridge_sentpos <- ggplot(df_sentpos_long, aes(x = sent_pos, y = sorting_policy, fill = ..x..)) +
  geom_density_ridges_gradient(scale = 3, rel_min_height = 0.01) +
  scale_fill_viridis(option = "C") +
  labs(title = 'Positive sentiment score by sorting policy') +
  theme_ipsum() +
    theme(
      legend.position="none",
      panel.spacing = unit(0.1, "lines"),
      strip.text.x = element_text(size = 8),
      plot.title = element_text(size = 12)
    )

p_ridge_sentneu <- ggplot(df_sentneu_long, aes(x = sent_neu, y = sorting_policy, fill = ..x..)) +
  geom_density_ridges_gradient(scale = 3, rel_min_height = 0.01) +
  scale_fill_viridis(option = "C") +
  labs(title = 'Neutral sentiment score by sorting policy') +
  theme_ipsum() +
    theme(
      legend.position="none",
      panel.spacing = unit(0.1, "lines"),
      strip.text.x = element_text(size = 8),
      plot.title = element_text(size = 12)
    )

p_ridge_sentneg <- ggplot(df_sentneg_long, aes(x = sent_neg, y = sorting_policy, fill = ..x..)) +
  geom_density_ridges_gradient(scale = 3, rel_min_height = 0.01) +
  scale_fill_viridis(option = "C") +
  labs(title = 'Negative sentiment score by sorting policy') +
  theme_ipsum() +
    theme(
      legend.position="none",
      panel.spacing = unit(0.1, "lines"),
      strip.text.x = element_text(size = 8),
      plot.title = element_text(size = 12)
    )


library(gridExtra)
grid.arrange(p_ridge_smog, p_ridge_lexdiv, p_ridge_cosine,
             p_ridge_sentpos, p_ridge_sentneu, p_ridge_sentneg,
             
             nrow = 3)

```


##Stats
```{r}

policy_categories <- data.frame(user_based = unlist(lapply(stats_smog_36$policy, function(x) strsplit(x,"_")[[1]][1])),
                                  editor_based = rep(c("not_pinned", "pinned"),18),
                                  structure_based = unlist(lapply(stats_smog_36$policy, function(x) substr(x, nchar(x)-1, nchar(x)))))


# All 36 policies

get_stats <- function(df_x){
  
  means <- c()
  medians <- c()
  SDs <- c()
  mins <- c()
  maxs <- c()
  
  # loop through all sorting policies
  for(i in 1:36){
    mins <- append(mins, as.numeric(summary(df_x[,i])[1]))
    maxs <- append(maxs, as.numeric(summary(df_x[,i])[6]))
    means <- append(means, as.numeric(summary(df_x[,i])[4]))
    medians <- append(medians, as.numeric(summary(df_x[,i])[3]))
    SDs <- append(SDs, as.numeric(sd(df_x[,1], na.rm = TRUE)))
  }
  
  stats_x_36 <- data.frame(mean = means, 
                              median = medians, 
                              SD = SDs,
                              min = mins,
                              max = maxs
                              )
  
  stats_x_36$policy <- sorting_policies_list_flat
  
  stats_x_36 <- cbind(stats_x_36, policy_categories)
  
  return(stats_x_36)
}

#get stats for all features
stats_smog_36 <- get_stats(df_smog)
stats_lexdiv_36 <- get_stats(df_lexdiv)
stats_cosine_36 <- get_stats(df_cosine1)
stats_sentpos_36 <- get_stats(df_sentpos)
stats_sentneu_36 <- get_stats(df_sentneu)
stats_sentneg_36 <- get_stats(df_sentneg)

options(scipen = 999)

colnames(stats_smog_36)

View(stats_sentneg_36)

# get averages by User-based
user_smog <- stats_smog_36 %>% group_by(user_based) %>% summarise(mean = mean(mean), median = mean(median), sd = mean(SD))
user_lexdiv <- stats_lexdiv_36 %>% group_by(user_based) %>% summarise(mean = mean(mean), median = mean(median), sd = mean(SD))
user_cosine <- stats_cosine_36 %>% group_by(user_based) %>% summarise(mean = mean(mean), median = mean(median), sd = mean(SD))
user_sentpos <- stats_sentpos_36 %>% group_by(user_based) %>% summarise(mean = mean(mean), median = mean(median), sd = mean(SD))
user_sentneu <- stats_sentneu_36 %>% group_by(user_based) %>% summarise(mean = mean(mean), median = mean(median), sd = mean(SD))
user_sentneg <- stats_sentneg_36 %>% group_by(user_based) %>% summarise(mean = mean(mean), median = mean(median), sd = mean(SD))

# get averages by editor-based
editor_smog <- stats_smog_36 %>% group_by(editor_based) %>% summarise(mean = mean(mean), median = mean(median), sd = mean(SD))
editor_lexdiv <- stats_lexdiv_36 %>% group_by(editor_based) %>% summarise(mean = mean(mean), median = mean(median), sd = mean(SD))
editor_cosine <- stats_cosine_36 %>% group_by(editor_based) %>% summarise(mean = mean(mean), median = mean(median), sd = mean(SD))
editor_sentpos <- stats_sentpos_36 %>% group_by(editor_based) %>% summarise(mean = mean(mean), median = mean(median), sd = mean(SD))
editor_sentneu <- stats_sentneu_36 %>% group_by(editor_based) %>% summarise(mean = mean(mean), median = mean(median), sd = mean(SD))
editor_sentneg <- stats_sentneg_36 %>% group_by(editor_based) %>% summarise(mean = mean(mean), median = mean(median), sd = mean(SD))


# get averages by structure-based
structure_smog <- stats_smog_36 %>% group_by(structure_based) %>% summarise(mean = mean(mean), median = mean(median), sd = mean(SD))
structure_lexdiv <- stats_lexdiv_36 %>% group_by(structure_based) %>% summarise(mean = mean(mean), median = mean(median), sd = mean(SD))
structure_cosine <- stats_cosine_36 %>% group_by(structure_based) %>% summarise(mean = mean(mean), median = mean(median), sd = mean(SD))
structure_sentpos <- stats_sentpos_36 %>% group_by(structure_based) %>% summarise(mean = mean(mean), median = mean(median), sd = mean(SD))
structure_sentneu <- stats_sentneu_36 %>% group_by(structure_based) %>% summarise(mean = mean(mean), median = mean(median), sd = mean(SD))
structure_sentneg <- stats_sentneg_36 %>% group_by(structure_based) %>% summarise(mean = mean(mean), median = mean(median), sd = mean(SD))



```


##Mann-Whitney U Test
```{r}
#1. SUM UP POLICY COLUMNS

# user-based:
get_avg_user_df <- function(df_x){
  
  df_avg_user <- data.frame(matrix(nrow = 5874, ncol = 0)) 
  
  # loop through 6 different policies
  for(i in seq(1,12,2)){ # 6 different policies
    
    avg_column <- rowMeans(df_x[,c(i, i+1,
                        i+12, i+13,
                        i+24, i+25)])
    
    df_avg_user <- cbind(df_avg_user, avg_column)
  }
  
  colnames(df_avg_user) <- unique(policy_categories$user_based)
  
  return(df_avg_user)
}


# editor-based:
get_avg_editor_df <- function(df_x){
  
  df_avg_editor <- data.frame(matrix(nrow = 5874, ncol = 0)) 
  
  # loop through 2 different policies
  for(i in 1:2){ 
    
    col_index <- seq(i,36,2)
    
    avg_column <- rowMeans(df_x[,col_index])
    
    df_avg_editor <- cbind(df_avg_editor, avg_column)
  }
  
  colnames(df_avg_editor) <- unique(policy_categories$editor_based)
  
  return(df_avg_editor)
}


# structure-based:
get_avg_structure_df <- function(df_x){
  
  df_avg_structure <- data.frame(matrix(nrow = 5874, ncol = 0)) 
  
  # loop through 3 different policies
  for(i in seq(1,36,12)){ 
    
    col_index <- i:(i+11)
    
    avg_column <- rowMeans(df_x[,col_index])
    
    df_avg_structure <- cbind(df_avg_structure, avg_column)
  }
  
  colnames(df_avg_structure) <- unique(policy_categories$structure_based)
  
  return(df_avg_structure)
}



#2. PAIRWISE DFs

# USERS

# metric
df_avg_user_smog <- get_avg_user_df(df_smog)
df_avg_user_lexdiv <- get_avg_user_df(df_lexdiv)
df_avg_user_cosine <- get_avg_user_df(df_cosine1)
df_avg_user_sentpos <- get_avg_user_df(df_sentpos)
df_avg_user_sentneu <- get_avg_user_df(df_sentneu)
df_avg_user_sentneg <- get_avg_user_df(df_sentneg)

# Generate all possible combinations of length 2 from 1:6
combinations <- combn(1:6, 2)

# for all possible combinations
for(i in 1:15){
  
  # get index of columns to compare
  col1_index <- combinations[1,i]
  col2_index <- combinations[2,i]
  
  # get colnames
  col1_name <- colnames(df_avg_user_sentneg)[col1_index]
  col2_name <- colnames(df_avg_user_sentneg)[col2_index]
  
  print(paste0(col1_name, " & ", col2_name))
  
  # create new dataframe
  df_temp <- df_avg_user_sentneg[,c(col1_index, col2_index)]
  
  print(df_temp)
  
  # pivot longer
  df_temp_longer <- df_temp %>% pivot_longer(cols = c(1,2), names_to = "policy", values_to = "values")
  
  # Mann Whitney U Test
  res <- wilcox.test(values ~ policy,
                 data = df_temp_longer)
  
  print(res$statistic)
  print(res$p.value)
}


# EDITORS
# metric
df_avg_editor_smog <- get_avg_editor_df(df_smog)
df_avg_editor_lexdiv <- get_avg_editor_df(df_lexdiv)
df_avg_editor_cosine <- get_avg_editor_df(df_cosine1)
df_avg_editor_sentpos <- get_avg_editor_df(df_sentpos)
df_avg_editor_sentneu <- get_avg_editor_df(df_sentneu)
df_avg_editor_sentneg <- get_avg_editor_df(df_sentneg)

# Generate all possible combinations of length 2 from 1:6
combinations <- combn(1:2, 2)

# for all possible combinations
for(i in 1:1){
  
  # get index of columns to compare
  col1_index <- combinations[1,i]
  col2_index <- combinations[2,i]
  
  # get colnames
  col1_name <- colnames(df_avg_editor_sentneg)[col1_index]
  col2_name <- colnames(df_avg_editor_sentneg)[col2_index]
  
  print(paste0(col1_name, " & ", col2_name))
  
  # create new dataframe
  df_temp <- df_avg_editor_sentneg[,c(col1_index, col2_index)]
  
  print(df_temp)
  
  # pivot longer
  df_temp_longer <- df_temp %>% pivot_longer(cols = c(1,2), names_to = "policy", values_to = "values")
  
  # Mann Whitney U Test
  res <- wilcox.test(values ~ policy,
                 data = df_temp_longer)
  
  print(res$statistic)
  print(res$p.value)
}




# STRUCTURE
# metric
df_avg_structure_smog <- get_avg_structure_df(df_smog)
df_avg_structure_lexdiv <- get_avg_structure_df(df_lexdiv)
df_avg_structure_cosine <- get_avg_structure_df(df_cosine1)
df_avg_structure_sentpos <- get_avg_structure_df(df_sentpos)
df_avg_structure_sentneu <- get_avg_structure_df(df_sentneu)
df_avg_structure_sentneg <- get_avg_structure_df(df_sentneg)

# Generate all possible combinations of length 2 from 1:6
combinations <- combn(1:3, 2)

# for all possible combinations
for(i in 1:3){
  
  # get index of columns to compare
  col1_index <- combinations[1,i]
  col2_index <- combinations[2,i]
  
  # get colnames
  col1_name <- colnames(df_avg_structure_sentneg)[col1_index]
  col2_name <- colnames(df_avg_structure_sentneg)[col2_index]
  
  print(paste0(col1_name, " & ", col2_name))
  
  # create new dataframe
  df_temp <- df_avg_structure_sentneg[,c(col1_index, col2_index)]
  
  print(df_temp)
  
  # pivot longer
  df_temp_longer <- df_temp %>% pivot_longer(cols = c(1,2), names_to = "policy", values_to = "values")
  
  # Mann Whitney U Test
  res <- wilcox.test(values ~ policy,
                 data = df_temp_longer)
  
  print(res$statistic)
  print(res$p.value)
}


options(scipen=0)


```







```{r}
# OLD

nrow(df_plot)
df_plot1 <- df_plot
df_plot1$n_rel <- round(df_plot1$n_rel, 4)

df_plot_merge <- merge(df_plot_general, df_plot1, by="n_rel", sort = FALSE, all.x = TRUE)
df_plot_merge <- df_plot_merge %>% arrange(n_rel)

# combine article dataframes
merge_article_dfs <- function(df_plot_article_list){
  
  # proportion of discussion read: 1/10,000 
  n_rel <- vector(mode="numeric", 10000)
  n_rel <- n_rel + 1/10000
  
  # create general dataframe
  df_plot_general <- data.frame(n_rel= cumsum(n_rel)) # nrow = 10k
  
  # loop through all df_article_plots
  for(i in df_plot_article_list){
    
    df_plot <- merge(df_plot, i, by=c("n_rel","sorting_policy"))
    
  }
  
}
```



##Plot graphs - 1 discussion
```{r, fig.height=6, fig.width=8}

for(i in 1:3){
  
  df_plot <- top_10p_SMOG(df_sort_list[[i]], sorting_policies_list[[i]]) # switch between hidden replies and trees
  p <- ggplot(df_plot, aes(x=n_rel, y = values)) +
    geom_line(aes(colour = sorting_policy), size = 0.8, alpha = 0.5) +
    labs(title = "Sorting of most readable comments by sorting policy", subtitle = "Discussion of article 3177 with 4675 comments") +
    xlab("n/N proportion of comments read") +
    ylab("proportion of overall 10% most readable comments") +
    theme_minimal() +
    theme(panel.grid = element_blank(),
          panel.border = element_rect(color = "black", fill = NA, size = 0.1)) +
    xlim(0, 1) + ylim(0, 1)
  
  print(p)
  
}

for(i in 1:3){
  
  df_plot <- top_10p_cosine1(df_sort_list[[i]], sorting_policies_list[[i]])
  p <- ggplot(df_plot, aes(x=n_rel, y = values)) +
    geom_line(aes(colour = sorting_policy), size = 0.8, alpha = 0.5) +
    labs(title = "Sorting of most relevant comments by sorting policy", subtitle = "Discussion of article 3177 with 4675 comments, Cosine similarity to article") +
    xlab("n/N proportion of comments read") +
    ylab("proportion of overall 10% most relevant comments") +
    theme_minimal() +
    theme(panel.grid = element_blank(),
          panel.border = element_rect(color = "black", fill = NA, size = 0.1)) +
    xlim(0, 1) + ylim(0, 1)
  
  print(p)
}

for(i in 1:3){
  df_plot <- top_10p_lexdiv(df_sort_list[[i]], sorting_policies_list[[i]])
  
  p <- ggplot(df_plot, aes(x=n_rel, y = values)) +
    geom_line(aes(colour = sorting_policy), size = 0.8, alpha = 0.5) +
    labs(title = "Sorting of most lexically diverse comments by sorting policy", subtitle = "Discussion of article 3177 with 4675 comments") +
    xlab("n/N proportion of comments read") +
    ylab("proportion of overall 10% most diverse comments") +
    theme_minimal() +
    theme(panel.grid = element_blank(),
          panel.border = element_rect(color = "black", fill = NA, size = 0.1)) +
    xlim(0, 1) + ylim(0, 1)
  print(p)
}

```

##Plot detrended graphs - 1 discussion 
```{r}
df_plot$values_detrend <- df_plot$values - df_plot$n_rel

p <- ggplot(df_plot, aes(x=n_rel, y = values_detrend)) +
    geom_line(aes(colour = sorting_policy), size = 0.8, alpha = 0.5) +
    labs(title = "Sorting of most lexically diverse comments by sorting policy", subtitle = "Discussion of article 3177 with 4675 comments") +
    xlab("n/N proportion of comments read") +
    ylab("proportion of most diverse comments - n/N") +
    theme_minimal() +
    theme(panel.grid = element_blank(),
          panel.border = element_rect(color = "black", fill = NA, size = 0.1)) 
print(p)

```


##Plot graphs - average
```{r, fig.height=6, fig.width=8}

p <- ggplot(df_plot_smog, aes(x=n_rel, y = values)) +
  geom_line(aes(colour = sorting_policy), size = 0.8, alpha = 0.5) +
  labs(title = "Sorting of most readable comments by sorting policy", subtitle = "Average over all discussions") +
  xlab("number of comments read") +
  ylab("proportion of overall 10% most readable comments") +
  theme_minimal() +
  theme(panel.grid = element_blank(),
        panel.border = element_rect(color = "black", fill = NA, size = 0.1)) +
  xlim(0, 1) + ylim(0, 1)

print(p)


p <- ggplot(df_plot_rel, aes(x=n_rel, y = values)) +
  geom_line(aes(colour = sorting_policy), size = 0.8, alpha = 0.5) +
  labs(title = "Sorting of most relevant comments by sorting policy", subtitle = "Discussion of article 3177 with 4675 comments, Cosine similarity to article") +
  xlab("number of comments read") +
  ylab("proportion of overall 10% most relevant comments") +
  theme_minimal() +
  theme(panel.grid = element_blank(),
        panel.border = element_rect(color = "black", fill = NA, size = 0.1)) +
  xlim(0, 1) + ylim(0, 1)

print(p)


p <- ggplot(df_plot_lexdiv, aes(x=n_rel, y = values)) +
  geom_line(aes(colour = sorting_policy), size = 0.8, alpha = 0.5) +
  labs(title = "Sorting of most lexically diverse comments by sorting policy", subtitle = "Discussion of article 3177 with 4675 comments") +
  xlab("number of comments read") +
  ylab("proportion of overall 10% most diverse comments") +
  theme_minimal() +
  theme(panel.grid = element_blank(),
        panel.border = element_rect(color = "black", fill = NA, size = 0.1)) +
  xlim(0, 1) + ylim(0, 1)
print(p)

```


##Plot detrended graphs - average 
```{r}
df_plot_smog$values_detrend <- df_plot_smog$values - df_plot_smog$n_rel
df_plot_rel$values_detrend <- df_plot_rel$values - df_plot_rel$n_rel
df_plot_lexdiv$values_detrend <- df_plot_lexdiv$values - df_plot_lexdiv$n_rel

p <- ggplot(df_plot_smog, aes(x=n_rel, y = values_detrend)) +
    geom_line(aes(colour = sorting_policy), size = 0.8, alpha = 0.5) +
    labs(title = "Sorting of most readable comments by sorting policy", subtitle = "average over X discussions") +
    xlab("n/N proportion of comments read") +
    ylab("proportion of most diverse comments") +
    theme_minimal() +
    theme(panel.grid = element_blank(),
          panel.border = element_rect(color = "black", fill = NA, size = 0.1)) 
print(p)

```

##Average values 
```{r}
df_plot_smog %>% group_by(sorting_policy) %>% summarise(avg_value = mean(values_detrend)) %>% arrange(desc(avg_value))

df_plot_rel %>% group_by(sorting_policy) %>% summarise(avg_value = mean(values_detrend)) %>% arrange(desc(avg_value))

df_plot_lexdiv %>% group_by(sorting_policy) %>% summarise(avg_value = mean(values_detrend)) %>% arrange(desc(avg_value))

```
